深度强化学习（Deep Reinforcement Learning, DRL）作为强化学习与深度学习相结合的前沿方法，近年来在多参数、多状态的复杂优化问题中展现出强大的潜力。在传统优化方法中，当参数空间维度高、状态数量多且动态变化频繁时，往往面临搜索空间庞大、模型泛化能力不足以及对环境适应性差等问题。
深度强化学习通过引入深度神经网络作为策略函数或价值函数的近似器，能够在高维连续状态空间中有效建模复杂的非线性关系，并在交互过程中不断学习最优的决策策略。本次研究方案中以控制参数为例，控制参数有6种参数，而同时对目标图像中识别目标识别产生影响的，还有各种场景参数，包括时间、日期、气溶胶、能见度等。而每一种控制参数，都有数个取值挡位，它们相互搭配所能选择的参数组合能达到上百种，而所有可能的参数组合共同构成深度强化学习的参数空间，维度数、状态数量已经符合深度强化学习能够解决的问题范畴。
在仿真平台种设置控制参数和环境参数之后，生成的目标图像，经过目标识别算法识别以后，得到的识别指标会与控制参数有复杂的非线性关系，可以采用深度学习的方式进行有效建模。同时，强化学习模型会通过改变控制参数的数值，得到新的图像指标，指导强化学习模型不断迭代每个控制参数组合对不同场景的图像指标价值。最后，从一个控制参数组合出发，不断选择选择周围价值最高的控制参数组合为下一步变化，直到收敛到一个控制参数组合上，这个控制参数组合就是最优控制参数组合，对不同的场景下识别识别目标都会有较好的指标结果。
而DQN算法是一种深度强化学习算法
